{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoderEstimator\n",
    "from pyspark.ml.feature import VectorAssembler,MinMaxScaler,ChiSqSelector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator \n",
    "from pyspark.sql.types import DoubleType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "except:\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"COVID\") \\\n",
    "        .config(\"hive.exec.dynamic.partition\", \"true\")\\\n",
    "        .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\") \\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha generado el siguiente dataframe\n",
      "+-----+----+--------+--------+----+----+---------------+------------+--------------+--------+-------------+----------+-------------+\n",
      "| SEXO|EDAD|EMBARAZO|DIABETES|EPOC|ASMA|INMUNOSUPRESION|HIPERTENSION|CARDIOVASCULAR|OBESIDAD|RENAL CRONICA|TABAQUISMO|TIPO PACIENTE|\n",
      "+-----+----+--------+--------+----+----+---------------+------------+--------------+--------+-------------+----------+-------------+\n",
      "|MUJER|64.0|      NO|      SI|  NO|  NO|             NO|          SI|            NO|      NO|           NO|        NO|  AMBULATORIO|\n",
      "|MUJER|52.0|      NO|      SI|  NO|  NO|             NO|          NO|            NO|      NO|           NO|        NO|HOSPITALIZADO|\n",
      "+-----+----+--------+--------+----+----+---------------+------------+--------------+--------+-------------+----------+-------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None\n",
      "Se tiene el siguiente numero de registros\n",
      "104307\n"
     ]
    }
   ],
   "source": [
    "def dataframe(rdd,features):\n",
    "    df=spark.read.csv(\"D:\\Descargas\\casos-asociados-a-covid-19.csv\",sep=\",\",header=True,encoding=\"UTF-8\",inferSchema=True)\n",
    "    df=df.filter(df[\"RESULTADO\"].isin(\"Positivo SARS-CoV-2\")) \n",
    "    df=df.select(features)\n",
    "    df = df.withColumn(\"EDAD\", df[\"EDAD\"].cast(DoubleType()))\n",
    "    \n",
    "    diz={\"NO APLICA\":\"NO\"}\n",
    "    f=\"SE IGNORA\"\n",
    "    df=df.filter(~df[\"EMBARAZO\"].isin(f) & ~df[\"DIABETES\"].isin(f) & ~df[\"EPOC\"].isin(f) \n",
    "                 & ~df[\"ASMA\"].isin(f) & ~df[\"INMUNOSUPRESION\"].isin(f) & ~df[\"HIPERTENSION\"].isin(f) \n",
    "                 & ~df[\"CARDIOVASCULAR\"].isin(f) & ~df[\"OBESIDAD\"].isin(f) & ~df[\"RENAL CRONICA\"].isin(f) \n",
    "                 & ~df[\"TABAQUISMO\"].isin(f) & ~df[\"EDAD\"].isin(0))\n",
    "    print(\"Se ha generado el siguiente dataframe\")\n",
    "    print(df.show(2))\n",
    "    print(\"Se tiene el siguiente numero de registros\")\n",
    "    print(df.count())\n",
    "    #df=pd.DataFrame(information)\n",
    "    \n",
    "    return df.select(features).replace(diz,1,\"EMBARAZO\")\n",
    "\n",
    "features=[\"SEXO\",\"EDAD\",\"EMBARAZO\",\"DIABETES\",\"EPOC\",\n",
    "          \"ASMA\",\"INMUNOSUPRESION\",\"HIPERTENSION\",\"CARDIOVASCULAR\",\"OBESIDAD\",\"RENAL CRONICA\",\n",
    "          \"TABAQUISMO\",\"TIPO PACIENTE\"]\n",
    "df=dataframe(1,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test= df.randomSplit([0.70,0.30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruebachi(df):\n",
    "    features2=[\"SEXO\",\"EDAD\",\"EMBARAZO\",\"DIABETES\",\"EPOC\",\n",
    "          \"ASMA\",\"INMUNOSUPRESION\",\"HIPERTENSION\",\"CARDIOVASCULAR\",\"OBESIDAD\",\"RENAL CRONICA\",\n",
    "          \"TABAQUISMO\",\"NEUMONIA\"]\n",
    "    stages=[]\n",
    "    for fea in features2:\n",
    "        string_Indexer =StringIndexer(inputCol=fea,outputCol=\"{}_Index\".format(fea))\n",
    "        stages+= [string_Indexer]\n",
    "    paciente_Index=StringIndexer(inputCol=\"TIPO PACIENTE\",outputCol=\"label\")\n",
    "    stages += [paciente_Index]\n",
    "    ai=[c+\"_Index\" for c in features2]+[\"EDAD\"]\n",
    "    a=VectorAssembler(inputCols=ai,outputCol=\"features\")\n",
    "    \n",
    "    css=ChiSqSelector(featuresCol=\"features\",outputCol=\"salidaf\",labelCol=\"label\",fpr=0.05)\n",
    "    stages+=[a,css]\n",
    "    pipe=Pipeline().setStages(stages)\n",
    "    Result=pipe.fit(df).transform(df)\n",
    "    return Result \n",
    "\n",
    "Result=pruebachi(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|TIPO PACIENTE|count|\n",
      "+-------------+-----+\n",
      "|  AMBULATORIO|35721|\n",
      "|HOSPITALIZADO|35499|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Result.select(\"features\",\"salidaf\",\"features\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes: DenseMatrix([[ 0.53466211, -1.35759011, -0.66195146, -0.32543677,  0.2849297 ,\n",
      "              -0.64444482, -0.19855877, -0.00614032, -0.23973089, -0.89166918,\n",
      "               0.08451465,  5.96085672]])\n",
      "intercepto: [0.3667877566693125]\n"
     ]
    }
   ],
   "source": [
    "def dataProcessing(df):\n",
    "    features2=[\"SEXO\",\"EMBARAZO\",\"DIABETES\",\"EPOC\",\n",
    "          \"ASMA\",\"INMUNOSUPRESION\",\"HIPERTENSION\",\"CARDIOVASCULAR\",\"OBESIDAD\",\"RENAL CRONICA\",\n",
    "          \"TABAQUISMO\"]\n",
    "    \n",
    "    stages=[]\n",
    "    for fea in features2:\n",
    "        string_Indexer =StringIndexer(inputCol=fea,outputCol=\"{}_Index\".format(fea))\n",
    "        ohe=OneHotEncoderEstimator(inputCols=[string_Indexer.getOutputCol()],outputCols=[\"{}_ohe\".format(fea)])\n",
    "        stages+= [string_Indexer,ohe]\n",
    "    paciente_Index=StringIndexer(inputCol=\"TIPO PACIENTE\",outputCol=\"label\")\n",
    "    stages += [paciente_Index]\n",
    "    ai=[c+\"_ohe\" for c in features2]+[\"EDAD\"]#[\"asma_ohe\",\"edad\"]\n",
    "    asu=VectorAssembler(inputCols=ai,outputCol=\"features_vec\")\n",
    "    stages+=[asu]\n",
    "    escalado=MinMaxScaler(inputCol=\"features_vec\",outputCol=\"features\")\n",
    "    stages+=[escalado]\n",
    "    mlr=LogisticRegression(labelCol=\"label\",featuresCol=\"features\")\n",
    "    stages+=[mlr]\n",
    "    pipe=Pipeline(stages=stages)\n",
    "    Model=pipe.fit(df)\n",
    "    print(\"Coeficientes: \" + str(Model.stages[-1].coefficientMatrix))\n",
    "    print(\"intercepto: \"+ str(Model.stages[-1].interceptVector))\n",
    "    return Model \n",
    "\n",
    "mod_train=dataProcessing(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(prediccion):\n",
    "    score=MulticlassClassificationEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=\"label\",\n",
    "    metricName=\"accuracy\")\n",
    "    evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"label\")\n",
    "    print(\"Elaccuracy del modelo es:\")\n",
    "    print(score.evaluate(prediccion))\n",
    "    print(\"La curva ROC del modelo es:\")\n",
    "    print(evaluator.evaluate(prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elaccuracy del modelo es:\n",
      "0.7258760478219046\n",
      "La curva ROC del modelo es:\n",
      "0.7651197274170215\n"
     ]
    }
   ],
   "source": [
    "predic=mod_train.transform(train)\n",
    "metricas(predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+----+----+---------------+------------+--------------+--------+-------------+----------+----+\n",
      "|  SEXO|EMBARAZO|DIABETES|EPOC|ASMA|INMUNOSUPRESION|HIPERTENSION|CARDIOVASCULAR|OBESIDAD|RENAL CRONICA|TABAQUISMO|EDAD|\n",
      "+------+--------+--------+----+----+---------------+------------+--------------+--------+-------------+----------+----+\n",
      "|HOMBRE|      NO|      NO|  NO|  NO|             NO|          NO|            NO|      SI|           NO|        NO|30.0|\n",
      "|HOMBRE|      NO|      NO|  NO|  NO|             NO|          NO|            NO|      SI|           NO|        NO|70.0|\n",
      "|HOMBRE|      NO|      NO|  NO|  NO|             NO|          NO|            NO|      NO|           NO|        NO|70.0|\n",
      "|HOMBRE|      NO|      SI|  NO|  NO|             NO|          NO|            NO|      SI|           NO|        NO|70.0|\n",
      "+------+--------+--------+----+----+---------------+------------+--------------+--------+-------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "def structDataframe(data):\n",
    "    features2=[\"SEXO\",\"EMBARAZO\",\"DIABETES\",\"EPOC\",\n",
    "          \"ASMA\",\"INMUNOSUPRESION\",\"HIPERTENSION\",\"CARDIOVASCULAR\",\"OBESIDAD\",\"RENAL CRONICA\",\n",
    "          \"TABAQUISMO\"]\n",
    "    schema= StructType(\n",
    "    [\n",
    "        StructField(\"SEXO\",StringType(),True),\n",
    "        StructField(\"EMBARAZO\",StringType(),True),\n",
    "        StructField(\"DIABETES\",StringType(),True),\n",
    "        StructField(\"EPOC\",StringType(),True),\n",
    "        StructField(\"ASMA\",StringType(),True),\n",
    "        StructField(\"INMUNOSUPRESION\",StringType(),True),\n",
    "        StructField(\"HIPERTENSION\",StringType(),True),\n",
    "        StructField(\"CARDIOVASCULAR\",StringType(),True),\n",
    "        StructField(\"OBESIDAD\",StringType(),True),\n",
    "        StructField(\"RENAL CRONICA\",StringType(),True),\n",
    "        StructField(\"TABAQUISMO\",StringType(),True),\n",
    "        StructField(\"EDAD\",DoubleType(),True)\n",
    "    ]\n",
    "    )\n",
    "    df=spark.createDataFrame(data,schema)\n",
    "    return df\n",
    "data=[[\"HOMBRE\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"SI\",\"NO\",\"NO\",30.0],[\"HOMBRE\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"SI\",\"NO\",\"NO\",70.0],\n",
    "      [\"HOMBRE\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",70.0],[\"HOMBRE\",\"NO\",\"SI\",\"NO\",\"NO\",\"NO\",\"NO\",\"NO\",\"SI\",\"NO\",\"NO\",70.0]]\n",
    "df2=structDataframe(data)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=mod_train.transform(df2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+\n",
      "|features                                                         |\n",
      "+-----------------------------------------------------------------+\n",
      "|[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0,0.24369747899159663]|\n",
      "|[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0,0.5798319327731093] |\n",
      "|[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.5798319327731093] |\n",
      "|[1.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0,0.5798319327731093] |\n",
      "+-----------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(\"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|probability                             |\n",
      "+----------------------------------------+\n",
      "|[0.7961253732094232,0.2038746267905768] |\n",
      "|[0.3449306169809247,0.6550693830190752] |\n",
      "|[0.4009118950773944,0.5990881049226056] |\n",
      "|[0.21360187041246081,0.7863981295875392]|\n",
      "+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(\"probability\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
